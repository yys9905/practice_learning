{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep_Learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMnTSvPMxWSiSOBU225sm/F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yys9905/practice_learning/blob/main/Deep_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "머신러닝 : 컴퓨터에게 학습을해 특정 문제를 해결할수 있는 능력을 만드는것\n",
        "\n",
        "딥러닝 - 머신러닝 기법중 하나(가이드라인이 불필요)\n",
        "\n",
        "AlphaGo\n",
        "기존의 머신러닝으로 만들어졌을 경우\n",
        "- 바둑 두는 법 가이드를 줌\n",
        "딥러닝으로 만들어졌을 경우\n",
        "- 컴퓨터가 try 와 error를 통해 터득함\n",
        "\n",
        "딥러닝으로 사전지식이 별로 없어도 만들수 있게됨\n",
        "\n",
        "뉴럴네트워크(뇌 신경망)를 이용해 러닝을 진행\n",
        "\n",
        "딥러닝이 잘하는 분야\n",
        "1. Image Classification / Object Detection\n",
        "2. Sequence Data 분석 & 예측 (ex.번역)"
      ],
      "metadata": {
        "id": "exVyu2usoV3i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "머신러닝 종류 \n",
        "Supervised Learning : 데이터에 정답이 있고 정답 예측 모델을 만들때 사용\n",
        "\n",
        "Unsupervised Learning : 데이터에 정답이 없을때 분류하게 하는것\n",
        "\n",
        "Reinforcement Learning : 상과 벌을 이용해 최종 점수를 높이는 방향으로 학습하게 하는것\n",
        "\n",
        "perceptron\n",
        "각각의 특징들이 끼치는 영향력(가중치:weight)을 곱해서 더한후 b(bias)를 더함\n",
        "\n",
        "*a1*x*w1* + *a2*x*w2* +... + *b*\n",
        "\n",
        "<img src = https://i.ibb.co/DQYs0dr/Perceptron.png>\n",
        "\n",
        "실제 데이터를 기준으로 오차를 최대한 줄이는 쪽으로 만들어보라고 시키는것.\n",
        "\n",
        "딥러닝\n",
        "perceptron에서 중간에 hidden layer을만들어 여러 perceptron들을 거쳐 예측하는것 - nuralnatwork\n",
        "layer를 여러게 만들면 딥뉴럴 네트워크라 함\n",
        "\n",
        "<img src=https://i.ibb.co/GV046FH/Neural-Network.png>\n",
        "\n",
        "feature extraction(특성추출) - 특성들을 추출해서 예측함"
      ],
      "metadata": {
        "id": "J9svYhKouOTh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=https://i.ibb.co/9WgSkMX/Neural-Network2.png>\n",
        "\n",
        "h1 = a1w1 + a2w2 + a3w3\n",
        "? = h1w7 + h2w8\n",
        "\n",
        "위를 기반으로 오차를 최소화하는 w값을 찾게 만드는것을 머신러닝이라 하고\n",
        "\n",
        "오차를 구함과 동시에 모델의 정확도를 평가하는 함수를\n",
        "손실함수(Loss function)이라함\n",
        "\n",
        "#$ 1\\over n$$∑(ŷ-y)^2$\n",
        "\n",
        "ŷ == 예측값\n",
        "\n",
        "y == 실제값\n",
        "\n",
        "제곱을하는 이유는 정수값을 예측할때 씀\n",
        "\n",
        "-$1\\over n$$Σ[ylog(ŷ) + (1 - y)log(1-ŷ)]$\n",
        "\n",
        "분류나 확률을 예측할때씀"
      ],
      "metadata": {
        "id": "TKx6dv1k0Wye"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "활성함수(Activation Function)\n",
        "\n",
        "<img src=https://i.ibb.co/hdwTKFC/active-function-removebg-preview.png>\n",
        "\n",
        "종류\n",
        "\n",
        "sigmoid\n",
        "\n",
        "0~1사이의 값으로 나타남\n",
        "\n",
        "# $1\\over 1 + e^{-x}$\n",
        "\n",
        "<img src=https://i.ibb.co/q98vgWN/desmos-graph.png>\n",
        "\n",
        "tanh(Hyperbolic tangent)\n",
        "\n",
        "-1~1사이의 값으로 나타남\n",
        "\n",
        "#$e^x-e^{-x}\\over {e^x+e^{-x}}$\n",
        "\n",
        "<img src= https://i.ibb.co/pPD0qy0/desmos-graph-1.png>\n",
        "\n",
        "Rectified Linear Units\n",
        "\n",
        "양수면 그대로, 음수면 0으로 나타남\n",
        "\n",
        "<img src = https://i.ibb.co/mtz8PHP/Rectified-Linear-Units.png>\n",
        "\n",
        "...\n",
        "\n",
        "활성함수 없이 예측 : 선형적이고 단순한 예측\n",
        "활성함수 포함한 예측 : 비선형적이고 복잡한 예측가능\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ElM3EMiBV4r9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#경사 하강법\n",
        "\n",
        "#새로운 $w_1 <=  w_1 - α{∂E\\over{∂w_1}}$\n",
        "\n",
        "$α{∂E\\over{∂w_1}}$ -> w1이 총손실 E에 얼마나 큰 영향을 끼치는지\n",
        "\n",
        "딥러닝 학습과정\n",
        "1. w값들을 랜덤으로 찍는다.\n",
        "2. w값 바탕으로 총손실 E를 계산한다\n",
        "3. 경사하강으로 새로운 w값을 업데이트한다.\n",
        "4. 2번과 3번을 반복(총손실E가 더이상 줄어들지 않을때까지.\n",
        "\n",
        "#local minima\n",
        "\n",
        "경사하강을 할때 실제 최저점을 찾기 위해 사용\n",
        "기울기만 빼는것이 아닌 임의의 learning rate(α)를 곱해서 뺌\n",
        "\n",
        "#learning rate(α) optimizer\n",
        "(학습 중간중간 learning rate를 어떤식으로 수정할지를 정함)\n",
        "- Momentum : 가속도를 유지\n",
        "- AdaGrad : 자주변하는 w는 작게,자주 변하지 않으면 크게\n",
        "- RMSProp : AdaGrad의 제곱\n",
        "- AdaDelta : AdaGrad인데 a가 너무 작아져서 학습 안되는걸 방지\n",
        "- Adam : RMSProp + Momentum\n",
        "\n",
        "여러개 써보고 모델과 어울리는것을 택해서 씀(보통 Adam)\n",
        "\n"
      ],
      "metadata": {
        "id": "2bqKfGhvfvp1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#텐서가 필요한 이유\n",
        "\n",
        "x1 x2 x3\n",
        "\n",
        "w1 w2 w3\n",
        "\n",
        "가있을때 계산하려면\n",
        "파이썬 코드를 쓰기 복잡해지고 귀찮아짐\n",
        "\n",
        "따라서 행렬을 이용하는데 행렬과 비슷하게 쓸수 있는\n",
        "텐서플로우 코드가 텐서임"
      ],
      "metadata": {
        "id": "KRKooMsFlPrg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#tensorflow 기초\n",
        "import tensorflow as tf\n",
        "\n",
        "tensor = tf.constant([3,4,5]) # 숫자, 리스트등을 담는 곳\n",
        "tensor2 = tf.constant([6,7,8])\n",
        "print(\"tensor + tensor2\")\n",
        "print(tensor + tensor2) \n",
        "print()\n",
        "\n",
        "tensor3 = tf.constant([[1,2],\n",
        "                       [3,4]])\n",
        "tensor4 = tf.constant([[5,6],\n",
        "                      [7,8]])\n",
        "print(\"tensor3*tensor4\")\n",
        "print(tensor3*tensor4)\n",
        "print()\n",
        "\n",
        "#사칙연산 : tf.add()  tf.subtract() tf.divide() tf.multiply\n",
        "#행렬곱 : tf.matmul()\n",
        "print(\"add(tensor,tensor2)\")\n",
        "print(tf.add(tensor, tensor2))\n",
        "print()\n",
        "print(\"matmul(tensor3, tensor4)\")\n",
        "print(tf.matmul(tensor3,tensor4))\n",
        "print()\n",
        "\n",
        "print(\"tf.zeros\")\n",
        "tensor5 = tf.zeros(10)\n",
        "print(tensor5)\n",
        "\n",
        "tensor6 = tf.zeros([2,2]) # tensor의 모양 shape(dimension)\n",
        "print(tensor6)\n",
        "print()\n",
        "\n",
        "print(\"tensor.shape\")\n",
        "print(tensor.shape)\n",
        "print(\"tensor3\")\n",
        "print(tensor3.shape)\n",
        "\n",
        "#cast 자료형 변환\n",
        "#variable 변형 가능 constant 변형 불가능\n",
        "w = tf.Variable(1.0) # weight ()안에 초기값 설정\n",
        "print(w)\n",
        "print(w.numpy())\n",
        "w.assign(2)\n",
        "print(w.numpy())\n"
      ],
      "metadata": {
        "id": "G9ja1Vv7tY_l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64942f67-1aa9-4265-ee3d-32f91452275b"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor + tensor2\n",
            "tf.Tensor([ 9 11 13], shape=(3,), dtype=int32)\n",
            "\n",
            "tensor3*tensor4\n",
            "tf.Tensor(\n",
            "[[ 5 12]\n",
            " [21 32]], shape=(2, 2), dtype=int32)\n",
            "\n",
            "add(tensor,tensor2)\n",
            "tf.Tensor([ 9 11 13], shape=(3,), dtype=int32)\n",
            "\n",
            "matmul(tensor3, tensor4)\n",
            "tf.Tensor(\n",
            "[[19 22]\n",
            " [43 50]], shape=(2, 2), dtype=int32)\n",
            "\n",
            "tf.zeros\n",
            "tf.Tensor([0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(10,), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[0. 0.]\n",
            " [0. 0.]], shape=(2, 2), dtype=float32)\n",
            "\n",
            "tensor.shape\n",
            "(3,)\n",
            "tensor3\n",
            "(2, 2)\n",
            "<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=1.0>\n",
            "1.0\n",
            "2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#간단한 선형 회귀 예측\n",
        "import tensorflow as tf\n",
        "\n",
        "# height = [170, 180, 175, 160]\n",
        "# size = [260, 270, 265, 255]\n",
        "height = 170\n",
        "size = 260\n",
        "\n",
        "a = tf.Variable(0.1)\n",
        "b = tf.Variable(0.2)\n",
        "\n",
        "def lossFunction():\n",
        "    y_bar = height * a+b\n",
        "    return tf.square(size - y_bar)\n",
        "\n",
        "#경사하강법을 이용해 변수를 업데이트 시켜주는것 learning_rate 지정안할시 자동지정\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=0.1) \n",
        "\n",
        "for i in range(300):\n",
        "    opt.minimize(lossFunction, var_list=[a,b])\n",
        "    # print(a.numpy(),b.numpy())\n",
        "print(height*a.numpy()+b.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXBy5D1wk5aO",
        "outputId": "7c3a48fb-5895-4f5a-d983-d71f792eb7e7"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "260.0000196695328\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "LzBVL7C_sVXu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}